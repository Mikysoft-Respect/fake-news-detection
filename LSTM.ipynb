{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the missing values\n",
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the label data, 0 means reliable while 1 means unreliable\n",
    "label_map = {\n",
    "    0: \"Real News\",\n",
    "    1: \"Fake News\"\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real News    10361\n",
       "Fake News     7924\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for data imbalance of the target variable\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3838"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many authors are there\n",
    "df['author'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tim O'neil                             1\n",
       "Emma-Kate Symons                       1\n",
       "Joyce Lau                              1\n",
       "The Hill                               1\n",
       "Robert Pear and Reed Abelson           1\n",
       "                                      ..\n",
       "Tyler Hicks                            1\n",
       "Nick Wingfield and Katie Benner        1\n",
       "Frances Robles and Timothy Williams    1\n",
       "Go Trump (UID 43400051)                1\n",
       "administrator                          1\n",
       "Name: author, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts().tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the author feature\n",
    "df.drop('author', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The id column is of no relevance\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The title of the news is pretty much explained in the text,so there is no need keeping the title variable\n",
    "df.drop('title',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>Real News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  Fake News\n",
       "1  Ever get the feeling your life circles the rou...  Real News\n",
       "2  Why the Truth Might Get You Fired October 29, ...  Fake News\n",
       "3  Videos 15 Civilians Killed In Single US Airstr...  Fake News\n",
       "4  Print \\nAn Iranian woman has been sentenced to...  Fake News"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning up the text\n",
    "\n",
    "#1) Removing Punctuations\n",
    "#2) Removing extra white spaces which occurs as a result of the initial removal of punctuations\n",
    "#3) Removing stopwords\n",
    "#4) Stemming the words which converts the word to its original form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_text = df['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING PUNCUTAIONS AND EXTRA WHITE SPACES\n",
    "import string\n",
    "punctuations = string.punctuation.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '’'\n",
    "punctuations.append(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = ''.join(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = [char for char in first_text if char not in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'D',\n",
       " 'e',\n",
       " 'm',\n",
       " ' ',\n",
       " 'A',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'W',\n",
       " 'e',\n",
       " ' ',\n",
       " 'D',\n",
       " 'i',\n",
       " 'd',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'E',\n",
       " 'v',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'S',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'y',\n",
       " 's',\n",
       " ' ',\n",
       " 'L',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'U',\n",
       " 'n',\n",
       " 't',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 'J',\n",
       " 'a',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'C',\n",
       " 'h',\n",
       " 'a',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 't',\n",
       " 'z',\n",
       " ' ',\n",
       " 'T',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 'B',\n",
       " 'y',\n",
       " ' ',\n",
       " 'D',\n",
       " 'a',\n",
       " 'r',\n",
       " 'r',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 'L',\n",
       " 'u',\n",
       " 'c',\n",
       " 'u',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'O',\n",
       " 'c',\n",
       " 't',\n",
       " 'o',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " '3',\n",
       " '0',\n",
       " ' ',\n",
       " '2',\n",
       " '0',\n",
       " '1',\n",
       " '6',\n",
       " ' ',\n",
       " 'S',\n",
       " 'u',\n",
       " 'b',\n",
       " 's',\n",
       " 'c',\n",
       " 'r',\n",
       " 'i',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'J',\n",
       " 'a',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'C',\n",
       " 'h',\n",
       " 'a',\n",
       " 'f',\n",
       " 'f',\n",
       " 'e',\n",
       " 't',\n",
       " 'z',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'm',\n",
       " 'p',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'A',\n",
       " 'm',\n",
       " 'e',\n",
       " 'r',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'F',\n",
       " 'o',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'U',\n",
       " 't',\n",
       " 'a',\n",
       " 'h',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'm',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " 't',\n",
       " 'e',\n",
       " 's',\n",
       " 'y',\n",
       " ' ',\n",
       " 'M',\n",
       " 'i',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'e',\n",
       " 'l',\n",
       " ' ',\n",
       " 'J',\n",
       " 'o',\n",
       " 'l',\n",
       " 'l',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'a',\n",
       " 'v',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 'a',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'u',\n",
       " 'n',\n",
       " 'd',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'C',\n",
       " 'r',\n",
       " 'e',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " 'B',\n",
       " 'Y',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " 'n',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'W',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'a',\n",
       " 'p',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'g',\n",
       " 'i',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'K',\n",
       " 'e',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'O',\n",
       " 'l',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " 'm',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " 'u',\n",
       " 'b',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'W',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'P',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'T',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'W',\n",
       " 'o',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 'k',\n",
       " '–',\n",
       " 'F',\n",
       " 'B',\n",
       " 'I',\n",
       " ' ',\n",
       " 'D',\n",
       " 'i',\n",
       " 'r',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'J',\n",
       " 'a',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'B',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 'a',\n",
       " 'c',\n",
       " 'c',\n",
       " 'o',\n",
       " 'r',\n",
       " 'd',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'H',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'D',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'c',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'a',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'l',\n",
       " 's',\n",
       " 'o',\n",
       " ' ',\n",
       " 'k',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 'n',\n",
       " 'd',\n",
       " 'w',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'p',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'u',\n",
       " 'r',\n",
       " 'n',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'w',\n",
       " 'h',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " 'i',\n",
       " 'n',\n",
       " 'f',\n",
       " 'a',\n",
       " 'm',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'e',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'n',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 'c',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'F',\n",
       " 'B',\n",
       " 'I',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'o',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'y',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'l',\n",
       " 'a',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'H',\n",
       " 'i',\n",
       " 'l',\n",
       " 'l',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " ' ',\n",
       " 'C',\n",
       " 'l',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'o',\n",
       " 'n',\n",
       " 's',\n",
       " ' ',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'r',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'D',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'c',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'l',\n",
       " 'e',\n",
       " 'v',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 'd',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " ' ',\n",
       " 'a',\n",
       " 'b',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'T',\n",
       " 'h',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'u',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'o',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 'v',\n",
       " 'i',\n",
       " 'a',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 't',\n",
       " 'w',\n",
       " 'e',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'r',\n",
       " 'o',\n",
       " 'm',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'R',\n",
       " 'e',\n",
       " 'p',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'e',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'i',\n",
       " 'r',\n",
       " 'm',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'A',\n",
       " 's',\n",
       " ' ',\n",
       " 'w',\n",
       " 'e',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'k',\n",
       " 'n',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'y',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 't',\n",
       " 'i',\n",
       " 'f',\n",
       " 'i',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'R',\n",
       " 'e',\n",
       " 'p',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " 'a',\n",
       " 'n',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'a',\n",
       " 'i',\n",
       " 'r',\n",
       " 'm',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'D',\n",
       " 'e',\n",
       " 'm',\n",
       " 'o',\n",
       " 'c',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'k',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'H',\n",
       " 'o',\n",
       " 'u',\n",
       " 's',\n",
       " 'e',\n",
       " ' ',\n",
       " 'I',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 'i',\n",
       " 'g',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'J',\n",
       " 'u',\n",
       " 'd',\n",
       " 'i',\n",
       " 'c',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'y',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'O',\n",
       " 'v',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " 'i',\n",
       " 'g',\n",
       " 'h',\n",
       " 't',\n",
       " ' ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'm',\n",
       " 'm',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'y',\n",
       " ' ',\n",
       " 'w',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'v',\n",
       " 'i',\n",
       " 'e',\n",
       " 'w',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'e',\n",
       " 'm',\n",
       " 'a',\n",
       " 'i',\n",
       " 'l',\n",
       " 's',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 'd',\n",
       " ' ',\n",
       " 'r',\n",
       " 'e',\n",
       " 'c',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'c',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'House Dem Aide We Didnt Even See Comeys Letter Until Jason Chaffetz Tweeted It By Darrell Lucus on October 30 2016 Subscribe Jason Chaffetz on the stump in American Fork Utah  image courtesy Michael Jolley available under a Creative CommonsBY license \\nWith apologies to Keith Olbermann there is no doubt who the Worst Person in The World is this week–FBI Director James Comey But according to a House Democratic aide it looks like we also know who the secondworst person is as well It turns out that when Comey sent his nowinfamous letter announcing that the FBI was looking into emails that may be related to Hillary Clintons email server the ranking Democrats on the relevant committees didnt hear about it from Comey They found out via a tweet from one of the Republican committee chairmen \\nAs we now know Comey notified the Republican chairmen and Democratic ranking members of the House Intelligence Judiciary and Oversight committees that his agency was reviewing emails it had recently discovered in order to see if they contained classified information Not long after this letter went out Oversight Committee Chairman Jason Chaffetz set the political world ablaze with this tweet FBI Dir just informed me The FBI has learned of the existence of emails that appear to be pertinent to the investigation Case reopened \\n— Jason Chaffetz jasoninthehouse October 28 2016 \\nOf course we now know that this was not the case  Comey was actually saying that it was reviewing the emails in light of “an unrelated case”–which we now know to be Anthony Weiners sexting with a teenager But apparently such little things as facts didnt matter to Chaffetz The Utah Republican had already vowed to initiate a raft of investigations if Hillary wins–at least two years worth and possibly an entire terms worth of them Apparently Chaffetz thought the FBI was already doing his work for him–resulting in a tweet that briefly roiled the nation before cooler heads realized it was a dud \\nBut according to a senior House Democratic aide misreading that letter may have been the least of Chaffetz sins That aide told Shareblue that his boss and other Democrats didnt even know about Comeys letter at the time–and only found out when they checked Twitter “Democratic Ranking Members on the relevant committees didnt receive Comeys letter until after the Republican Chairmen In fact the Democratic Ranking Members didn receive it until after the Chairman of the Oversight and Government Reform Committee Jason Chaffetz tweeted it out and made it public” \\nSo lets see if weve got this right The FBI director tells Chaffetz and other GOP committee chairmen about a major development in a potentially politically explosive investigation and neither Chaffetz nor his other colleagues had the courtesy to let their Democratic counterparts know about it Instead according to this aide he made them find out about it on Twitter \\nThere has already been talk on Daily Kos that Comey himself provided advance notice of this letter to Chaffetz and other Republicans giving them time to turn on the spin machine That may make for good theater but there is nothing so far that even suggests this is the case After all there is nothing so far that suggests that Comey was anything other than grossly incompetent and tonedeaf \\nWhat it does suggest however is that Chaffetz is acting in a way that makes Dan Burton and Darrell Issa look like models of responsibility and bipartisanship He didnt even have the decency to notify ranking member Elijah Cummings about something this explosive If that doesnt trample on basic standards of fairness I dont know what does \\nGranted its not likely that Chaffetz will have to answer for this He sits in a ridiculously Republican district anchored in Provo and Orem it has a Cook Partisan Voting Index of R25 and gave Mitt Romney a punishing 78 percent of the vote in 2012 Moreover the Republican House leadership has given its full support to Chaffetz planned fishing expedition But that doesnt mean we cant turn the hot lights on him After all he is a textbook example of what the House has become under Republican control And he is also the Second Worst Person in the World About Darrell Lucus \\nDarrell is a 30something graduate of the University of North Carolina who considers himself a journalist of the old school An attempt to turn him into a member of the religious right in college only succeeded in turning him into the religious rights worst nightmarea charismatic Christian who is an unapologetic liberal His desire to stand up for those who have been scared into silence only increased when he survived an abusive threeyear marriage You may know him on Daily Kos as Christian Dem in NC  Follow him on Twitter DarrellLucus or connect with him on Facebook  Click here to buy Darrell a Mello Yello Connect'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = ''.join(text1)\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    #Changing all texts into lower case\n",
    "    text = text.lower()\n",
    "    #Removing punctuations\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’”—'\n",
    "    text = [char for char in text if char not in punctuations]\n",
    "    text = ''.join(text)\n",
    "    #Removing extra white spaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide we didnt even see comeys letter...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ever get the feeling your life circles the rou...</td>\n",
       "      <td>Real News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the truth might get you fired october 29 2...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>videos 15 civilians killed in single us airstr...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>print an iranian woman has been sentenced to s...</td>\n",
       "      <td>Fake News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0  house dem aide we didnt even see comeys letter...  Fake News\n",
       "1  ever get the feeling your life circles the rou...  Real News\n",
       "2  why the truth might get you fired october 29 2...  Fake News\n",
       "3  videos 15 civilians killed in single us airstr...  Fake News\n",
       "4  print an iranian woman has been sentenced to s...  Fake News"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'youre',\n",
       " 'youve',\n",
       " 'youll',\n",
       " 'youd',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'shes',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'thatll',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'should',\n",
       " 'shouldve',\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'arent',\n",
       " 'couldn',\n",
       " 'couldnt',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'hadn',\n",
       " 'hadnt',\n",
       " 'hasn',\n",
       " 'hasnt',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'isn',\n",
       " 'isnt',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " 'mightnt',\n",
       " 'mustn',\n",
       " 'mustnt',\n",
       " 'needn',\n",
       " 'neednt',\n",
       " 'shan',\n",
       " 'shant',\n",
       " 'shouldn',\n",
       " 'shouldnt',\n",
       " 'wasn',\n",
       " 'wasnt',\n",
       " 'weren',\n",
       " 'werent',\n",
       " 'won',\n",
       " 'wont',\n",
       " 'wouldn',\n",
       " 'wouldnt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuations from the stopwords to make it uniform\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords = ' '.join(stopwords)\n",
    "stopwords = [char for char in stopwords if char not in string.punctuation]\n",
    "stopwords = ''.join(stopwords)\n",
    "stopwords = stopwords.split()\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The stopwords are the most frequently occuring words as usual\n",
    "#Stop words add no benefits when building models\n",
    "def removing_stopwords(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    stopwords = ' '.join(stopwords)\n",
    "    stopwords = [char for char in stopwords if char not in string.punctuation]\n",
    "    stopwords = ''.join(stopwords)\n",
    "    stopwords = stopwords.split()\n",
    "    text = text.split()\n",
    "    text = [word for word in text if word not in stopwords]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEMMINGOR LEMMATIZATION\n",
    "def stemming(text):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    text = text.split()\n",
    "    text = [p_stemmer.stem(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for empty string tweets\n",
    "blanks = []\n",
    "for i,lb,text in df.itertuples():\n",
    "    if type(text) == str:\n",
    "        if text == '':\n",
    "            blanks.append(i)\n",
    "            \n",
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks = []\n",
    "for i,lb,text in df.itertuples():\n",
    "    if type(text) == str:\n",
    "        if text.isspace():\n",
    "            blanks.append(i)\n",
    "            \n",
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real News    56.663932\n",
       "Fake News    43.336068\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
